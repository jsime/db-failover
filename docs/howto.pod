=begin html

<!--
Source of this documentation is in howto.pod file, do not edit howto.html - it
should be regenerated, using make, after changes are done to pod file.
-->

=end html

=head1 NAME

failover.pl - tool to simplify failover of PostgreSQL servers

=head1 HOWTO

This howto will guide you through setting failover script in simple
master->slave replication cluster.

=head2 Basic assumptions

In the whole howto, I use following names/ips/paths:

=over

=item * vito - master server in replicated setup (ip: 192.168.0.101, interface
eth0)

=item * michael - slave server in replicated setup (ip: 192.168.0.102,
interface eth0)

=item * godfather - name that always points to master database (ip:
192.168.0.100)

=item * /pgdata - data directory for PostgreSQL, on both vito and michael

=item * postgres - name of system user that PostgreSQL server is running on, and
also name of superuser account

=back

Finally, I assume that the starting point of the setup procedure is when you
have both vito and michael running PostgreSQL, with some kind of WAL-based
replication (Streaming Replication, OmniPITR, or anything else that handles
archive and restore of xlog files).

It also assumes that application connects to database using 192.168.0.101 ip.

=head2 Setup procedure

=head3 Shared IP setup

On both, vito and michael, you have to add new interfaces, which will be an alias
of existing main interface - eth0. The exact manner of setting up the interface
aliases depends on your OS and distribution, though the general concepts are the
same.

On Debian/Ubuntu, you have to modify F</etc/network/interfaces> file, which will
most likely have inside something like:

    auto lo
    iface lo inet loopback

    auto eth0
    iface eth0 inet static
        address 192.168.0.101
        netmask 255.255.255.0
        gateway 192.168.0.1

To this file, on B<both> machines we have to add new block:

    iface eth0:0 inet static
        address 192.168.0.100
        netmask 255.255.255.0

It is important that there wouldn't be C<auto eth0:0> - as we don't want this
interface to be automatically brought up on system boot.

If you have arping program, you might want to add also:

    up arping -c 1 -U 192.168.0.100 -I eth0 > /dev/null 2>&1 || true

This will make sure that when failover will happen, arpcaches of all machines
in LAN will get cleared so the IP takeover will be faster.

I<Warning>

There are (on Ubuntu) two, not compatible versions of arping, in packages:

=over

=item * iputils-arping

=item * arping

=back

Command line shown above is compatible with version of arping from
I<iputils-arping> package.

So, full addition to F</etc/network/interfaces> should look:

    iface eth0:0 inet static
        address 192.168.0.100
        netmask 255.255.255.0
        up arping -c 1 -U 192.168.0.100 -I eth0 > /dev/null 2>&1 || true

After adding it to both machines, run on vito:

    $ ifup eth0:0

This should bring up this interface, which should make it possible to ping
192.168.0.100 from any host in lan. Do try:

    $ ping 192.168.0.100

Assuming it works, verify that your PostgreSQL listens on all interfaces. This
can be done by simply trying to connect (using I<psql>) to godfather host. If it
works - we're fine. If not - make sure that in F</pgdata/postgresql.conf> on
both machines, B<listen_addresses> is set to C<*>:

    listen_addresses = '*'

If you had to change it - you will need to restart PostgreSQL.

At this moment, you should have:

=over

=item * eth0:0 interface configured on both machines, with the same IP

=item * eth0:0 interface up on vito and down on michael

=item * PostgreSQL on 192.168.0.100 accessible to application

=back

Final step is very simple - switch your application to use shared IP. How it is
done depends on application, but basically in some db configuration you have to
change I<192.168.0.101> to I<192.168.0.100>. Most likely you will also need to
restart your application.

=head3 Configuring failover.pl

First you have to decide what account, on what host to put F<failover.pl> and its
F<.ini> file on. The account doesn't matter at all, it doesn't have to be root.

To make F<failover.pl> work, you need to make sure that the account you'll run
it from will have password less access (over ssh) to:

=over

=item * root@vito (for bringing down eth0:0 interface)

=item * root@michael (for bringing up eth0:0 interface)

=item * postgres@michael (for promoting slave to standalone)

=back

This can be done by doing:

    $ ssh-keygen

and then appending generated F<id_dsa.pub> key to F<~/.ssh/authorized_keys> on
all accounts listed above.

Next you need to find out what is the name of trigger file. This is written in
F</pgdata/recovery.conf> file, as either:

    trigger_file = '/path/to/trigger-file'

( in case of streaming replication ), or as an option to restore program in

    restore_command = '....'

Which option is it depends on what program is used for restore_command, for
F<omnipitr-restore> it's B<--finish-trigger>/B<-f>

Once you have this file path, you are ready to create F<failover.ini> file. For
my example, let's assume the trigger file is supposed to be
F</tmp/trigger.file>.

The configuration file may be located in the same directory as F<failover.pl>,
in your home directory, or at F</etc/db-failover/failover.ini>. The program will
use the first of those, in that order, that exists and which is readable. If you
want, you can also place the file anywhere else and use the C<-c> argument to
F<failover.pl> to manually specify the location. For this howto, we'll assume
the F<failover.pl> and F<failover.ini> are in the same directory.

First, we need to define the shared address:

    [ip-takeover]
    host = godfather

You can alternatively use the IP address in place of hostnames anywhere you like.

With the shared name (which should resolve to the virtual IP assigned to the
aliased interfaces) set up, each of the database hosts should be defined next. A
[common] section will also be set up so that we can avoid defining repeated
values. Any options set in the [common] section will be inherited by all other
sections that use those particular options, though you can override that by
also setting it in a specific section.

    [common]
    user = postgres
    interface = eth0:0
    method = ifupdown
    database = postgres
    pg-user = postgres
    pg-port = 5432
    pg-data = /pgdata
    omnipitr = /opt/omnipitr

    [host-michael]
    host = michael

    [host-vito]
    host = vito

In our examples here, the only things that differ so far between the two PostgreSQL
hosts are their network hostnames, so we're able to put everything else into the
[common] section.

We also need to define a location where backups will be stored, so that the process
of demoting a host to a slave will know where to retrieve a clean backup to
restore.

    [backup]
    path = /pgbackups

Because this example does not define a host, F<failover.pl> will treat it as a
locally-accessible path on the machine from which this program is run. If you wish
to store and retrieve the backups (generated with the relevant OmniPITR tools)
on a remote host over ssh/rsync, then include appropriate values for both the
C<host> and C<user> settings, in addition to the C<path>.

Finally, last B<required> section, is data-check, which can define queries to
verify proper database operation. Any number of these sections may be defined
so that you can test as many or as few pieces of your database as you like. Each
data-check section should be named uniquely, though if you only have one it may
be safely named just "data-check".

    [data-check]
    query = select 2 > 1
    result = t

The query value should be any read-only query that you expect to succeed and return
a single scalar value. The result should be a string which will match the expected
(and successful) result of that query. In the case of the example query above, it
is expected to return a boolean value, which PostgreSQL represents by default as
either 't' or 'f'.

F<failover.pl> will use I<host> from I<shared-ip> section as host to connect to
to run all the db checks.

And that's about it. Full F<failover.ini> would be:

    [common]
    user = postgres
    interface = eth0:0
    method = ifupdown
    database = postgres
    pg-user = postgres
    pg-port = 5432
    pg-data = /pgdata
    omnipitr = /opt/omnipitr

    [host-michael]
    host = michael

    [host-vito]
    host = vito

    [backup]
    path = /pgbackups

    [data-check]
    query = select 2 > 1
    result = t

For remote shell access (required to run backups, move recovery.conf files into
place, enable/disable network interfaces, etc.), if sshd on any of your remote
systems runs on a port other than 22, the correct solution is to set this in
your F<~/.ssh/config> file:

    Host michael
        Port 22222

At this point, you should be ready to begin running F<failover.pl>. Running it
without any arguments (assuming your F<failover.ini> is in one of the default
locations), will produce a summary of your settings, with all of the options set
in the [common] section applied appropriately. If you want to test your configuration
and connectivity to all the hosts defined, run:

    failover.pl --test

Promoting a new master host is as straight forward (assuming your configuration
is correct) as:

    failover.pl --promote <host>

Where I<host> matches one of your C<[host-*]> sections. Demotion is very similar:

    failover.pl --demote <host>

With the assumption that I<vito> is currently the master, we can switch their roles
by doing:

    failover.pl --promote michael --demote vito

The program will also operate on the command line arguments in an order which ensures
one master server is present. Thus, if you run:

    failover.pl --demote vito --promote michael

The promotion of I<michael> will be performed first, before demoting I<vito>.

=head1 COPYRIGHT

The OmniPITR project is Copyright (c) 2009-2012 OmniTI. All rights reserved.

